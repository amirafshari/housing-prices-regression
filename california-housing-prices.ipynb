{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ocean_proximity count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=['<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'NEAR BAY', 'ISLAND'], y=data['ocean_proximity'].value_counts(), data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.pie(x=data['ocean_proximity'].value_counts(), labels=['<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'NEAR BAY', 'ISLAND'], autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where are the most populated areas?\n",
    "#### population density recongnition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind='hexbin', x='longitude', y='latitude',gridsize=40, figsize=(13,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind='scatter', x='longitude', y='latitude', alpha=0.1, c='blue', edgecolor='black', figsize=(10,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind='scatter', x='longitude', y='latitude',\n",
    "             alpha=0.5, s=data['population']/100,\n",
    "             c='median_house_value', cmap=plt.get_cmap('jet'),\n",
    "             figsize=(13,8),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = data.corr()\n",
    "corr_matrix['median_house_value'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['median_house_value', 'median_income', 'total_rooms', 'housing_median_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(data[attributes], figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind='scatter', x='median_income', y='median_house_value', edgecolor='black', c='blue', alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(bins=50, figsize=(20,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better intuition for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because we have varied scales, we put each box in a distinct plot \n",
    "plt.figure(figsize=(14,10))\n",
    "\n",
    "n = 0\n",
    "for c in ['total_rooms', 'total_bedrooms', 'population', 'households']:\n",
    "    n += 1\n",
    "    plt.subplot(2, 2, n)\n",
    "    data.boxplot(column=[c],grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Handling\n",
    "# population\n",
    "indices = data[data.loc[:,'population'] > 4700].index\n",
    "data.loc[indices,'population'] = 4700\n",
    "\n",
    "# total_rooms\n",
    "indices = data[data.loc[:,'total_rooms'] > 8000].index\n",
    "data.loc[indices,'total_rooms'] = 8000\n",
    "\n",
    "# total_bedrooms\n",
    "indices = data[data.loc[:,'total_bedrooms'] > 1700].index\n",
    "data.loc[indices,'total_bedrooms'] = 1700\n",
    "\n",
    "# households\n",
    "indices = data[data.loc[:,'households'] > 2000].index\n",
    "data.loc[indices,'households'] = 2000\n",
    "\n",
    "# New Features and New Correlations\n",
    "data['rooms_per_household'] = data['total_rooms']/data['households']\n",
    "data['bedrooms_per_room'] = data['total_bedrooms']/data['total_rooms']\n",
    "data['population_per_household'] = data['population']/data['households']\n",
    "\n",
    "# Imputing\n",
    "data_cat = data['ocean_proximity']\n",
    "data_num = data.drop('ocean_proximity', axis=1)\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "imputer.fit_transform(data_num)\n",
    "\n",
    "# One-Hot Encoding\n",
    "encoder = LabelBinarizer()\n",
    "\n",
    "data_cat_encoded = encoder.fit_transform(data_cat)\n",
    "data_cat_encoded = pd.Series(data_cat_encoded.tolist())\n",
    "\n",
    "data = pd.concat([data_cat_encoded, data_num], axis=1)\n",
    "\n",
    "data = data.rename(columns={0: 'ocean_proximity'})\n",
    "\n",
    "data['op_0'] = [e[0] for e in data['ocean_proximity']]\n",
    "data['op_1'] = [e[1] for e in data['ocean_proximity']]\n",
    "data['op_2'] = [e[2] for e in data['ocean_proximity']]\n",
    "data['op_3'] = [e[3] for e in data['ocean_proximity']]\n",
    "data['op_4'] = [e[4] for e in data['ocean_proximity']]\n",
    "\n",
    "data = data.drop(['ocean_proximity'], axis=1)\n",
    "\n",
    "# Spliting\n",
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Seprating Labels from Features\n",
    "y_train = train_set['median_house_value'] #Labels\n",
    "x_train = train_set.drop('median_house_value', axis=1) #Features\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "x_train = pd.DataFrame(scaler.fit_transform(x_train), columns=x_train.columns, index=x_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check outliers again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "\n",
    "n = 0\n",
    "for c in ['total_rooms', 'total_bedrooms', 'population', 'households']:\n",
    "    n += 1\n",
    "    plt.subplot(2, 2, n)\n",
    "    data.boxplot(column=[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check distributions again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(bins=50, figsize=(20,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New features & New correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = data.corr()\n",
    "corr_matrix['median_house_value'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num.median().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data = x_train.iloc[:5]\n",
    "some_labels = y_train.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.predict(some_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_mse = np.sqrt(mean_squared_error(y_train, lin_reg.predict(x_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(x_train, y_train)\n",
    "tree_predictions = tree_reg.predict(x_train)\n",
    "\n",
    "tree_mse = np.sqrt(mean_squared_error(tree_predictions, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTree overfits our data, so we split our data into 10 distinct subsets (folds). In this way our model picks 1 subset for evaluation and 9 subsets for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(tree_reg, x_train, y_train, scoring='neg_mean_squared_error', cv=10)\n",
    "tree_rmse = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(x_train, y_train)\n",
    "rf_predictions = forest_reg.predict(x_train)\n",
    "\n",
    "rf_mse = mean_squared_error(rf_predictions, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(-scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
